Word Sense Disambiguation (WSD) is the task of automatically  selecting the most related sense for a word occurring in a context. WSD is considered as a main step in the course of approaching language understanding beyond the surface of the words and has been intensively studied in Natural Language Processing (NLP)~\cite{navigli2012quick}. WSD is used in Machine Translation~\cite{chan2007word,costa2014statistical}, Information Retrieval~\cite{zhong2012word,na2011enriching}, or Entity Linking~\cite{moro2014entity}.

Typically, the methods for approaching WSD are classified into knowledge-based, supervised, and unsupervised. Knowledge-based approaches use available structured knowledge% and apply algorithms by considering the structural and the connectivity properties of the model
~\cite{agirre2014random,miller2012using}. Often, the systems exploit WordNet~\cite{fellbaum1998wordnet} as the sense inventory, together with graph-based methods~\cite{agirre2010graph,guo2010combining}.
Supervised approaches learn a computational model based on large amounts of annotated data. While these two approaches show competitive results in practice, they both have to face the knowledge acquisition bottleneck. This is a particular problem in specific domains or scarce-resource languages~\cite{pilehvar2014large}. As an alternative, unsupervised approaches address WSD using only information extracted from existing corpora, such as various term co-occurrence indicators~\cite{di2013clustering}.

As a paradigm, multilingual and cross-lingual WSD focus on lexical substitution in a target language. The creation of large knowledge resources such as BabelNet~\cite{navigli2010babelnet} and DBPedia~\cite{auer2007dbpedia} have opened up new possibilities for solving these tasks with multilingual data. For example, Navigli and Ponzetto~\shortcite{navigli2012joining} exploit BabelNet to develop their graph-based monolingual and bilingual WSD across main European languages.

Cross-lingual Word Sense Disambiguation (CL-WSD) targets disambiguation of one word in a source language while translating to a target language. SemEval-2010~\cite{lefever2010semeval} and SemEval-2013~\cite{lefever2013semeval} provide an evaluation platform for term disambiguation  from English to Dutch, German, Italian, Spanish, and French. % The participating systems mostly exploit the Europarl corpus~\footnote{\url{http://www.statmt.org/europarl/}}, a domain specific parallel corpora. For instance, Levefer~\shortcite{lefever2011parasense}, Rudnick et al.~\shortcite{rudnick2013hltdi}, and Gompel et al.~\shortcite{gompel2013wsd2} align the words in the parallel corpus and then follow classification-based approaches on the context features, while Silberer et al.~\shortcite{silberer2010uhd} exploit the connection between nodes after building a multilingual co-occurrence graph. 
As the task introduces the Europarl corpus~\cite{europarl} as the main resource, many participating systems exploit these parallel corpora to overcome the knowledge acquisition bottleneck~\cite{lefever2011parasense,rudnick2013hltdi}. However, these methods are not applicable for many languages and domains due to the scarcity of bilingual corpora. Persian, for instance, suffers from the lack of reliable and comprehensive knowledge resources as well as parallel corpora. In such cases, unsupervised methods based on monolingual corpora (together with bilingual lexica) are preferable, if not the only available option~\cite{sofianopoulos2012implementing}. %Generally, such methods are based on monolingual corpora in combination with bilingual lexica~\cite{sofianopoulos2012implementing}. 
For example, Bungum et al.~\shortcite{bungum2013improving} find the probable translations of a context in the source language and identify the best using a language model of the target language. Duque et al.~\shortcite{duqueco} build a co-occurrence graph in the target language, and test a variety of graph-based algorithms for identifying the best translation match.

In terms of combining WSD and Semantic Vector Representations of words, Chen et al.~\shortcite{chen2014unified} use knowledge-based WSD to identify distinct representations for different senses of the same term. Our approach for CL-WSD is the opposite of this: starting from general vector representations of terms, it identifies their different senses in context. %mainly based on the relation between semantic vector representation of the words in the target language.  
As vector representations we used two state-of-the-art methods: Word2Vec and GloVe. Word2Vec~\cite{mikolov2013efficient} introduces a highly incremental and scalable method such that when trained on large datasets, it makes it possible to capture many linguistic subtleties (e.g. similar relation between Italy and Rome in comparison to France and Paris). More recently, GloVe~\cite{pennington2014glove} shows superior results in exploiting the implicit knowledge within corpora. 

%We target the problem of CL-WSD from English to Persian language using an unsupervised solution based on vector representation of the words.
In order to evaluate our system, following the format of SemEval CL-WSD task~\cite{lefever2013semeval}, %we created and make available a new test collection for Persian. In fact, 
we contributed Persian as a new language to the framework of the task by providing a new test collection. We compared our approach and the CO-Graph system~\cite{duqueco} on this new evaluation collection, observing the advantages of using vector representations in WSD.

The contributions of the work are two-fold:
\vspace{-0.2cm}
\begin{enumerate}
\item Creating a new CL-WSD benchmark for Persian.
\vspace{-0.2cm}
\item Providing a new state-of-the-art for unsupervised CL-WSD methods, based on the use of vector representations of words.
\end{enumerate}
\vspace{-0.2cm}

The remainder of this paper is organized as follows: Section~\ref{sec:relatedwork} investigates the available Persian language resources. Section~\ref{sec:persian_collection} describes in detail the creation of the new Persian CL-WSD evaluation task. Then, Section~\ref{sec:methodology} explains our unsupervised approach to solve the introduced task, followed by the outline of our experiments in Section~\ref{sec:experiments}. %Results are finally concluded in Section~\ref{sec:conclusion}.
